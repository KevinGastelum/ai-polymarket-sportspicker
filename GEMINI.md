# ğŸ† GEMINI Workflow Guide: AI PolyMarket Sports Picker

This guide is designed to help you (the user) and the Antigravity Agent build the AI PolyMarket Sports Picker efficiently.

---

## ğŸ¯ Project Overview

**Goal**: Build a $0-cost ML-powered sports prediction platform integrated with Polymarket.

### Core Components
| Component | Technology | Status |
|-----------|------------|--------|
| ML Models | Python, TensorFlow/PyTorch | ğŸ”² TODO |
| Data Pipeline | Polymarket CLOB API, Sports APIs | ğŸ”² TODO |
| Backend | Supabase (Free Tier) | ğŸ”² TODO |
| Web App | Next.js/Vite + Vanilla CSS | ğŸ”² TODO |
| Mobile App | React Native / Expo | ğŸ”² TODO |
| Training | Google Colab / Kaggle | ğŸ”² TODO |

---

## ğŸ—£ï¸ Effective Prompting

### âœ… Good Prompts for This Project
- "Create the Polymarket sports data scraper in `src/tools/polymarket_scraper.py` using the CLOB API"
- "Set up the Supabase schema for predictions, results, and user data"
- "Build the Historical Model training notebook for Google Colab"
- "Design the prediction dashboard with a dark mode, glassmorphism UI"

### âŒ Avoid These
- "Make the app" (Too vague)
- "Train the model" (Which model? What data?)

---

## ğŸ”„ Development Workflows

### 1. Data Pipeline Development
```
Step 1: Build Polymarket scraper â†’ src/tools/polymarket_client.py
Step 2: Build sports history fetcher â†’ src/tools/sports_data.py
Step 3: Create data processing pipeline â†’ src/data/processor.py
Step 4: Store in Supabase â†’ src/tools/supabase_client.py
```

### 2. Model Development Cycle
```
Step 1: Prepare training data â†’ notebooks/data_prep.ipynb
Step 2: Train Historical Model â†’ notebooks/historical_model.ipynb
Step 3: Train Sentiment Model â†’ notebooks/sentiment_model.ipynb
Step 4: Train Hybrid Model â†’ notebooks/hybrid_model.ipynb
Step 5: Export models â†’ models/
```

### 3. Live Prediction Pipeline
```
Step 1: Fetch current Polymarket sports markets
Step 2: Run predictions through all 3 models
Step 3: Log predictions to Supabase
Step 4: Post-event: Label as correct/wrong
Step 5: Update rolling accuracy metrics
```

### 4. Frontend Development
```
Step 1: Set up Next.js project â†’ web/
Step 2: Create design system â†’ web/styles/
Step 3: Build core components â†’ web/components/
Step 4: Connect to Supabase â†’ web/lib/supabase.ts
Step 5: Deploy to Vercel (Free)
```

---

## ğŸ”Œ Key Integrations

### Polymarket CLOB API
```python
# Base URL
CLOB_API_URL = "https://clob.polymarket.com"

# Key Endpoints
GET /markets          # List all markets
GET /markets/{id}     # Get specific market
GET /trades           # Get trade history

# Filter for sports markets
# Markets have tags: "sports", "nba", "nfl", "soccer", etc.
```

### Supabase Schema (Proposed)
```sql
-- Predictions table
predictions (
  id UUID PRIMARY KEY,
  market_id TEXT,
  sport TEXT,
  event_name TEXT,
  predicted_outcome TEXT,
  historical_confidence FLOAT,
  sentiment_confidence FLOAT,
  hybrid_confidence FLOAT,
  actual_outcome TEXT,
  is_correct BOOLEAN,
  created_at TIMESTAMP
)

-- Model metrics table
model_metrics (
  id UUID PRIMARY KEY,
  model_type TEXT,  -- 'historical', 'sentiment', 'hybrid'
  accuracy_7d FLOAT,
  accuracy_30d FLOAT,
  total_predictions INT,
  updated_at TIMESTAMP
)
```

---

## ğŸ¨ UI/UX Guidelines

### Design System Requirements
- **Theme**: Dark mode primary, light mode optional
- **Colors**: Deep navy/charcoal base, vibrant accent (electric blue, neon green)
- **Typography**: Inter or Outfit (Google Fonts)
- **Effects**: Glassmorphism cards, subtle gradients, micro-animations
- **Layout**: Clean, spacious, professional

### Key Screens
1. **Dashboard**: Live predictions, model accuracy, trending markets
2. **Predictions Feed**: Card-based list with confidence scores
3. **Analytics**: Charts showing model performance over time
4. **Profile**: User stats, notification preferences

---

## ğŸ“ Proposed Project Structure

```
polymarket-predictor/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ polymarket_client.py   # CLOB API client
â”‚   â”‚   â”œâ”€â”€ sports_data.py         # Historical sports data
â”‚   â”‚   â””â”€â”€ supabase_client.py     # Supabase operations
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ processor.py           # Data preprocessing
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ historical.py          # Historical model inference
â”‚       â”œâ”€â”€ sentiment.py           # Sentiment model inference
â”‚       â””â”€â”€ hybrid.py              # Hybrid model inference
â”œâ”€â”€ notebooks/                      # Colab/Kaggle training notebooks
â”‚   â”œâ”€â”€ data_prep.ipynb
â”‚   â”œâ”€â”€ historical_model.ipynb
â”‚   â”œâ”€â”€ sentiment_model.ipynb
â”‚   â””â”€â”€ hybrid_model.ipynb
â”œâ”€â”€ web/                           # Next.js web app
â”œâ”€â”€ mobile/                        # React Native app
â”œâ”€â”€ models/                        # Exported model weights
â””â”€â”€ supabase/                      # Supabase migrations & functions
```

---

## ğŸ’° Free Resources Checklist

| Resource | Use Case | Limit |
|----------|----------|-------|
| Google Colab | Model training | 12hr sessions, GPU access |
| Kaggle Notebooks | Backup training | 30hr/week GPU |
| Supabase Free | Backend/DB | 500MB, 50K requests/mo |
| Vercel Free | Web hosting | 100GB bandwidth |
| Expo | Mobile builds | Limited builds/mo |

---

## ğŸš€ Phase-by-Phase Roadmap

### Phase 1: Foundation
- [ ] Set up Supabase project
- [ ] Build Polymarket scraper
- [ ] Create data collection pipeline

### Phase 2: Models
- [ ] Prepare training datasets
- [ ] Train Historical Model (Colab)
- [ ] Train Sentiment Model (Colab)
- [ ] Train Hybrid Model (Colab)

### Phase 3: Live System
- [ ] Build prediction API
- [ ] Implement live logging
- [ ] Create accuracy tracking

### Phase 4: Frontend
- [ ] Design UI/UX mockups
- [ ] Build web app (Next.js)
- [ ] Build mobile app (React Native)

### Phase 5: Launch
- [ ] Create TikTok content
- [ ] Create Instagram content
- [ ] Beta launch
- [ ] Iterate based on feedback

---

## ğŸ”§ Troubleshooting

### API Rate Limits
Polymarket CLOB API has rate limits. Implement:
- Request caching
- Exponential backoff
- Batch requests where possible

### Model Overfitting
Historical models can overfit. Mitigate by:
- Using the Hybrid model as primary
- Tracking live accuracy separately from backtest accuracy
- Weighting recent predictions more heavily

### Free Tier Limits
Monitor Supabase usage. If approaching limits:
- Archive old predictions
- Optimize queries
- Consider data compression

---

## ğŸ“ Quick Reference

| Command | Description |
|---------|-------------|
| `python src/tools/polymarket_client.py` | Test Polymarket connection |
| `python src/agent.py "Get sports markets"` | Run agent task |
| `npm run dev` (in web/) | Start web development server |
| `npx expo start` (in mobile/) | Start mobile dev server |
